{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating an Expressive 3D Morphable Model\n",
    "\n",
    "#### Prerequisites\n",
    "\n",
    "- Access to a 3D facial shape model of identity\n",
    "- Access to a 3D facial shape model of expression (a 'blendshape' model)\n",
    "\n",
    "The authors of:\n",
    "\n",
    "> Zhu, Xiangyu, et al. \"Face alignment across large poses: A 3d solution.\" CVPR 2016\n",
    "\n",
    "Provide data [on their website](http://www.cbsr.ia.ac.cn/users/xiangyuzhu/projects/3DDFA/main.htm) which can be used to bootstrap the expression model, and the LSFM model can be used for identity variation. As an example, we show loading this data into the format we need to proceed, and then demonstrate building the combined expression/identity model. The file this example follows is:\n",
    "```\n",
    "300W-3D.zip\n",
    "```\n",
    "and also requires access to the following file (the LSFM model):\n",
    "```\n",
    "all_all_all.mat\n",
    "```\n",
    "place the two files together in a directory and unzip the zip file in place. Replace `DATA_PATH` with the parent folder path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import scipy.io as sio\n",
    "import menpo.io as mio\n",
    "import menpo3d.io as m3io\n",
    "\n",
    "from menpo.shape import TriMesh, PointCloud\n",
    "from menpo.model import PCAModel\n",
    "\n",
    "# Replace DATA_PATH with the path to your data. It should have subdirectories:\n",
    "#  300W-3D/\n",
    "#  all_all_all.mat\n",
    "DATA_PATH = Path('~/Dropbox/itwmm_src_data/').expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],   
   "source": [
    "def generate_id_exp_model(data_path):\n",
    "    # Load the LSFM ID model\n",
    "    lsfm_model = m3io.import_lsfm_model(data_path / 'all_all_all.mat')\n",
    "    \n",
    "    # The number of ID and expression deformation components\n",
    "    n_id = lsfm_model.n_active_components\n",
    "    n_exp = 28 \n",
    "    \n",
    "    # Multiply the LSFM components with a scale factor, and bake in the eigenvalues.\n",
    "    # The scale factor is to normalize weightings between ID and expression models.\n",
    "    scale = np.sqrt(lsfm_model.eigenvalues[:n_id])\n",
    "    i_raw = lsfm_model.components[:n_id] * scale[:, None]\n",
    "    \n",
    "    # Load the expression deformations from the data, and again scale for balancing\n",
    "    scale_exp_mean = 1.0006846894227463e-05\n",
    "    scale_exp_comps = scale_exp_mean / 2.5\n",
    "    e_raw = sio.loadmat(str(data_path / '300W-3D' / 'Code' / 'Model_Exp.mat'))['w_exp'].T[:-1] * scale_exp_comps \n",
    "    e_mean = sio.loadmat(str(data_path / '300W-3D' / 'Code' / 'Model_Exp.mat'))['mu_exp'].T * scale_exp_mean\n",
    "    \n",
    "    # We now just need to combine the two models.\n",
    "    id_ind = np.arange(n_id)\n",
    "    exp_ind = np.arange(n_id, n_id + n_exp)\n",
    "    components = np.zeros([n_id + n_exp, i_raw.shape[1]])\n",
    "    components[id_ind] = i_raw\n",
    "    components[exp_ind] = e_raw\n",
    "    mean_combined = TriMesh(lsfm_model.mean().points + e_mean.reshape((-1,3)), lsfm_model.mean().trilist) \n",
    "    \n",
    "    # iBUG 68 landmarks \n",
    "    lms_vertex_indices = [\n",
    "        21868, 22404, 22298, 22327, 43430, 45175, 46312, 47132, 47911,\n",
    "        48692, 49737, 51376, 53136, 32516, 32616, 32205, 32701, 38910,\n",
    "        39396, 39693, 39934, 40131, 40843, 41006, 41179, 41430, 13399,\n",
    "        8161,  8172,  8179,  8185,  5622,  6881,  8202,  9403, 10764,\n",
    "        1831,  3887,  5049,  6214,  4805,  3643,  9955, 11095, 12255,\n",
    "        14197, 12397, 11366,  5779,  6024,  7014,  8215,  9294, 10267,\n",
    "        10922,  9556,  8836,  8236,  7636,  6794,  5905,  7264,  8223,\n",
    "        9063, 10404,  8828,  8228,  7509\n",
    "    ]\n",
    "    lms = PointCloud(mean_combined.points[lms_vertex_indices])\n",
    "\n",
    "    # Initialize a Menpo PCA Model from the raw data.\n",
    "    # Note that we fix the eigenvalues to 1, as we choose to rescale\n",
    "    # the components to 'bake-in' the eigenvalues above.\n",
    "    shape_model = PCAModel.init_from_components(components, \n",
    "                                                np.ones(components.shape[1]), \n",
    "                                                mean_combined, \n",
    "                                                lsfm_model.n_samples, \n",
    "                                                True)\n",
    "    \n",
    "    return shape_model, lms, id_ind, exp_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Blend the ID and expression models into one, and note\n",
    "# The indices into the model for both indivual components.\n",
    "shape_model, lms, id_ind, exp_ind = generate_id_exp_model(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# generate a random expression to see if it's sensible\n",
    "n_c = shape_model.n_components\n",
    "\n",
    "# The std. dev weighting to use\n",
    "sigma = 1\n",
    "\n",
    "weights = np.random.multivariate_normal(np.zeros(n_c), np.eye(n_c) * sigma, 1).ravel()\n",
    "\n",
    "synthesized_vector = shape_model.mean_vector + np.sum(weights[:, None] * shape_model.components, axis=0)\n",
    "synthesized_instance = shape_model.template_instance.from_vector(synthesized_vector)\n",
    "synthesized_instance.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting the combined ID/expression shape model\n",
    "\n",
    "To use this model we just need to save it out and load it in to the fitting notebooks. Note that we need to save out some metadata along with the raw PCA basis to be able to use this again in the future. In particular, we need:\n",
    "\n",
    "- The record of which components are identitiy and which are expression (`id_ind` and `exp_ind`)\n",
    "- The vertex indices of the sparse set of landmarks on the model\n",
    "\n",
    "We also need the ITW texture model we use to be in perfect correspondence with the shape model provided here, and for the landmarks in data we fit to be of the same configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mio.export_pickle(\n",
    "    {\n",
    "        'shape_model': shape_model,\n",
    "        'id_ind': id_ind,\n",
    "        'exp_ind': exp_ind,\n",
    "        'lms': lms\n",
    "    }, \n",
    "    DATA_PATH / 'id_exp_shape_model.pkl',\n",
    "    protocol=4, overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
